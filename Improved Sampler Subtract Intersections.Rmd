---
title: "Improved Sampler 2"
author: "Justin Weltz"
date: "4/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Reading in Data

We read in the MWM data and connectome matrices:
```{r cars}
mwm<-read.csv("data/MWM.csv")
mwmlong<-read.csv("data/MWMlong.csv")
chasssy<-read_excel("data/CHASSSYMM3AtlasLegends.xlsx")
```


```{r}
filePaths <- list.files("data/Connectomes",
                        "\\.csv$", full.names = TRUE)
connectome_matlist <- lapply(filePaths,function(x) read.csv(x,header=FALSE) %>% as.matrix())

network <- connectome_matlist[[1]]
network2 <- connectome_matlist[[2]]
```

Binarizing Matrix Function:
```{r}
# takes matrix (matr) and binarizes each element 
# based on a threshold (strict less than)

binarize_matrix <- function(matr, threshold) {
  
  for (i in 1:length(matr)) {
    matr[[i]] <- ifelse(matr[[i]] < threshold, 0, 1)
  }
  
  return(matr)
}

```
Normalize
```{r}
normalize <- function(x){ 
  return((x-min(x))/(max(x)-min(x)))}
```

Difference in Networks (binarized matrices)
```{r}
# returns vector of number of edge deletions and additions needed for 
# binarized matr_1 to become binarized matr_2

network_diffs <- function(matr_1,matr_2,threshold) {
  
  # frequency matrix of -1,0,1 resulting from difference of bin. matrices
  diff_freq_matr <- (binarize_matrix(matr_2,threshold) - 
    binarize_matrix(matr_1,threshold)) %>% 
    table() %>%
    as.matrix()
  # Avoid NAs
  if(is.na(diff_freq_matr[3]))
    diff_freq_matr[3]=0
  
  return(diff_freq_matr[c(1,3)])
}
```

```{r}
network_diffs <- function(matr_1,matr_2,threshold) {
  
  # frequency matrix of -1,0,1 resulting from difference of bin. matrices
  diff_freq_matr <- binarize_matrix(matr_2,threshold) - 
    binarize_matrix(matr_1,threshold)
  add=sum(diff_freq_matr==1)
  del=sum(diff_freq_matr==-1)
  return(c(del,add))
}
```

Remove Subdivision 8 from the dataset
```{r}
indices=(chasssy$Subdivisions_7!="8_CSF")
indices=indices[-length(indices)]
for (i in 1:length(connectome_matlist)) {
  connectome_matlist[[i]] <- connectome_matlist[[i]][indices,indices]
}
```

Indexing Matrices by Runno
```{r}

# create list of identifiers corresponding to list of connectomes
regexp <- "N[[:digit:]]{5}"
matrix_labels <- lapply(filePaths,function(x) str_extract(x,regexp)) %>% unlist()

# takes vector of runnos (string format) and finds corresponding matrices
# returns vector of matrices if they exist, otherwise returns empty matrix

find_connects <- function(runnos) {
  
  idxs <- which(matrix_labels %in% runnos)
  
  if (length(idxs) == 0) {
    print("No matches")
    return(matrix())
  }
  
  return(connectome_matlist[idxs])
}

```

Final Distance Function
```{r}
distance <- function(data){
add_B0_diff=rep(0,length(data))
del_B0_diff=rep(0,length(data))
add_B1_diff=rep(0,length(data))
del_B1_diff=rep(0,length(data))

for(i in 1:length(data)){
      #deletions from B_i to B0
      del_B0_diff[i]=network_diffs(data[[i]],B0,0.5)[1]
      #additions form B_i to B0
      add_B0_diff[i]=network_diffs(data[[i]],B0,0.5)[2]
      #deletions from B_i to B1
      del_B1_diff[i]=network_diffs(data[[i]],B1,0.5)[1]
      #additions from B_i to B1
      add_B1_diff[i]=network_diffs(data[[i]],B1,0.5)[2]
}
differences <- cbind(add_B0_diff, del_B0_diff, add_B1_diff, del_B1_diff)
return(differences)
}

```


Final Null Distribution Function

```{r}
null_distribution <- function(samples, iter, response, B0, B1, data, differences){
  distr <- matrix(NA, samples, 4)
  for (i in 1:samples){
    distr[i,] <- colMeans(sampler(iter, response, B0, B1, data, differences, null = T))
  }
  names <- c("phi_00", "phi_01", "phi_10",  "phi_11")
  colnames(distr)<- names
  return(distr)
}

```

Intersection Function 
```{r}

intersect <- function(data){
tracker = matrix(T,R,R)
for (i in 1:(n-1)){
  inter = data[[i]] == data[[i+1]]
  tracker = tracker & inter
}

return(sum(as.vector(tracker)))

}

```

***IMPORTANT PART***
Probit Gibbs Sampler Function with Subtraction of Group Intersection
```{r}
require(truncnorm)
#Adding Intersection - If the edge is common across all networks tham there's no reason to account for it in variability.
sampler <- function(iter, response, B0, B1, data, differences, intersection, null){
  

#Extract Differences
  
add_B0_diff <- differences[,1]
del_B0_diff <- differences[,2]
add_B1_diff <- differences[,3]
del_B1_diff <- differences[,4]

#Iteration and Initialization of Value
R=dim(B0)[1]
n= length(data)
Cs=sample(x=c(0,1), size = n, replace = T)
Psi=matrix(0.9999,2,2)
Psi_save = matrix(0,iter,4)

#New Parameters to initialize
latent_Z = rep(0,n)
beta= 0


#Save new parameters
beta_save = c(NA,iter)
Cs_save = matrix(NA, iter, n)
latent_Z_save = matrix(NA, iter, n)
prob_C0_save = matrix(NA, iter, n)

if (null){
  response = sample(size = n, x =response,replace = F )
}


for(t in 1:iter){
  
  #draw latent zs with gibbs step
  for (i in 1:n){
    if(Cs[i] == 1){
    latent_Z[i] = rtruncnorm(1,a= 0, b = Inf,response[i]*beta,1)
    }
    if(Cs[i] == 0){
    latent_Z[i] = rtruncnorm(1,a = -Inf,b =  0,response[i]*beta,1)
    }
    
  }
  
  #Save the latent Zs
  latent_Z_save[t,] <- latent_Z

  #update beta with gibbs step
  
  beta = rnorm(1,sum(response*latent_Z)/sum(response^2), sqrt(1/sum(response^2)))
  beta_save[t] = beta
  
  # draw latent Cs with Gibbs Step
  
  #Calculate Probability C=0
  logpc0=del_B0_diff*log(Psi[1,1])+add_B0_diff*log(Psi[1,2])
  logpc1=del_B1_diff*log(Psi[2,1])+add_B1_diff*log(Psi[2,2])
  prob_C0 = 1/(1+exp(logpc1-logpc0))
  #prob_C0 =  (Psi[1,1]^del_B0_diff*Psi[1,2]^add_B0_diff)/ (Psi[1,1]^del_B0_diff*Psi[1,2]^add_B0_diff + Psi[2,1]^del_B1_diff*Psi[2,2]^add_B1_diff)
  
    #Save Prob_C0
  prob_C0_save[t,] <- prob_C0
  
#Now draw using the probability
  for (i in 1:n){
    Cs[i] = sample(x =  c(0,1), size = 1, prob= c(prob_C0[i], 1-prob_C0[i]))
  }
  
    #Save the classifications
  Cs_save[t,] <- Cs 
  
  
  # Update Psi
  add_B0=0
  del_B0=0
  add_B1=0
  del_B1=0
  
  #For each network, if the network has been grouped around B0, then compute the additions and subtractions needed to get from B_i to B0
  #if the network has been grouped around B1, then compute the additions and subtractions needed to get from B_i to B1
  for (i in 1:n){
    if (Cs[i]==0){
      #deletions from B_i to B0
      del_B0=del_B0+del_B0_diff[i]
      #additions form B_i to B0
      add_B0=add_B0+add_B0_diff[i]
    }
    else{
      #deletions from B_i to B1
      del_B1=del_B1+del_B1_diff[i]
      #additions from B_i to B1
      add_B1=add_B1+add_B1_diff[i]
    }
  }
  
  #Calculate the number in the B_1 class and B_0 class:
  num_B1 <- sum(Cs)
  num_B0 <- n-sum(Cs)
  
  # Update and sample phi_00 variable - probability of having to delete an edge to get to B0
  Psi[1,1]=rbeta(1,del_B0+1,1 + (R^2-intersection)*num_B0 - del_B0)
  
  #Update and sample phi_01 variable - probability of having to add an edge to get to B0
  Psi[1,2]=rbeta(1,add_B0+1,1 + (R^2-intersection)*num_B0 - add_B0)
  
  #Update and sample phi_10 variable - probability of having to delete an edge to get to B1 
  Psi[2,1]=rbeta(1,del_B1+1,1 + (R^2-intersection)*num_B1 - del_B1)
  
    #Update and sample phi_11 variable - probability of having to add an edge to get to B1
  Psi[2,2]=rbeta(1,add_B1+1,1 + (R^2 - intersection)*num_B1 - add_B1)
  
  #save the Psi parameters
  Psi_save[t,] = c(Psi[1,1], Psi[1,2], Psi[2,1], Psi[2,2])
}
full_parameters <- cbind(Psi_save, beta_save)
names <- c("phi_00", "phi_01", "phi_10",  "phi_11", "beta")
colnames(full_parameters)<- names
parameter_list <- list()
parameter_list[[1]] <- full_parameters
parameter_list[[2]] <- latent_Z_save
parameter_list[[3]] <- Cs_save
parameter_list[[4]] <- prob_C0_save
return(parameter_list)
}
```

Real Dataset
```{r}
##Choose Response
choose_res=function(mwmlong,matrix_labels,string){
  #Choose the average speed of  every mouse
  #String is the desired variable to choose
  result=rep(0,length(matrix_labels))
  i=1
  for (label in matrix_labels) {
    result[i]=mwmlong %>% 
    filter(grepl(label,runno,fixed = TRUE)) %>% 
    select(string) %>% 
    unlist() %>% 
    mean(na.rm=TRUE)
    i=i+1
  }
  return(result)
}
#Choose avg.sw.speed as a response and normalize
avg.sw.speed=choose_res(mwmlong = mwmlong, matrix_labels = matrix_labels, "Average.SW.Speed") %>% 
           normalize()
B0=connectome_matlist[[which.min(avg.sw.speed)]]
B1=connectome_matlist[[which.max(avg.sw.speed)]]
## Remove the extremal networks
data=connectome_matlist[-c(which.min(avg.sw.speed),which.max(avg.sw.speed))]
R=dim(data[[1]])[1]
n=length(data)
pis=avg.sw.speed[-c(which.min(avg.sw.speed),which.max(avg.sw.speed))]
#functions that need to be run in order to establish arguments for sampler
distances <- distance(data)
intersection <- intersect(data)
samp2 <- sampler(10000, pis, B0, B1, data, distances, intersection, null = F)
```

Real Dataset-top 3 Most relevant connectnome to high sw.speed: 310-254, 147-91, 214-51 
```{r}
connect_freq=matrix(0,R,R)
membership_prob=samp2[[3]] %>% colMeans()
##calculate the strength of connectnomes related to C=1
for (i in 1:length(data)) {
  connect_freq=connect_freq+data[[i]]*membership_prob[i]
}
which(connect_freq==max(connect_freq), arr.ind = T)
```

```{r}
which(connect_freq==sort(connect_freq,decreasing = T)[3], arr.ind = T)
which(connect_freq==sort(connect_freq,decreasing = T)[5], arr.ind = T)
```

Example of Analysis on Simulated Data Set

```{r}
n=20
R=200
#Initialize the pis - stand in for standardized memory metric
unsort_pis=runif(n)

#sort the pis so that they correspond to the networks that vary from B0 to B1
pis <- sort(unsort_pis)
data_set <- list()

#Create two extreme networks
B0 <- matrix(sample(c(1,0),R^2,replace = TRUE), nrow = R, ncol = R)

B1 <- matrix(sample(c(1,0),R^2,replace = TRUE), nrow = R, ncol = R)


#Create networks as linear combinations (sort of) of these two networks
combos <- 1:n/(n+1)

for (i in 1:n){
  prob <- B0*(1-combos[i]) + B1*(combos[i])
  new_data = matrix(NA, nrow = R, ncol = R)
  for (k in 1:R){
    for (j in 1:R){
      new_data[k,j] = sample(x = c(1,0),prob = c(prob[k,j], 1-prob[k,j]), size = 1)
    }
  }
  data_set[[i]]= new_data
}


data = data_set

#functions that need to be run in order to establish arguments for sampler
distances <- distance(data)
intersection <- intersect(data)

#sampler
samp1 <- sampler(10000, pis, B0, B1, data, distances,intersection, null = T)
hist(samp1[[1]][,5])
samp2 <- sampler(10000, pis, B0, B1, data, distances, intersection, null = F)
hist(samp2[[1]][,5])
```


